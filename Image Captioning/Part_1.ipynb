{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import re\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import efficientnet\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "keras.utils.set_random_seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.Download the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_file = keras.utils.get_file(\n",
    "#     fname=\"Flickr8k_Dataset.zip\",\n",
    "#     origin=\"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\",\n",
    "#     extract=True # ファイルを展開する\n",
    "# )\n",
    "# image_file = keras.utils.get_file(\n",
    "#     fname=\"Flickr8k_text.zip\",\n",
    "#     origin=\"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\",\n",
    "#     extract=True # ファイルを展開する\n",
    "# )\n",
    "# text_file = pathlib.Path(text_file).parent / \"Flickr8k_text\" / \"Flickr8k_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images\n",
    "IMAGES_PATH = \"./data/Flickr8k_Dataset\"\n",
    "\n",
    "# 画像の寸法\n",
    "IMAGE_SIZE = (299,299)\n",
    "\n",
    "# 語彙のサイズ\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# 固定長\n",
    "SEQ_LENGTH = 25\n",
    "\n",
    "# 画像埋め込みとトークン埋め込みの次元\n",
    "ENBED_DIM = 512\n",
    "\n",
    "# Feed-forwardネットワークのレイヤー単位\n",
    "FF_DIM = 64\n",
    "\n",
    "# 他のトレーニングパラメータ\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.Preparing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_captions_data(filename):\n",
    "    \"\"\"キャプション（テキスト）データを読み込み、対応する画像にマッピングする\n",
    "    \n",
    "    Args:\n",
    "        filename: キャプションデータを含むテキストファイルへのパス\n",
    "        \n",
    "    Returns:\n",
    "        caption_mapping: 画像名と対応するキャプションをマッピングするディクショナリ\n",
    "        text_data: 利用可能なすべてのキャプションを含むリスト\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename) as caption_file:\n",
    "        caption_data = caption_file.readlines()\n",
    "        caption_mapping = {}\n",
    "        text_data = []\n",
    "        images_to_skip = set()\n",
    "\n",
    "        for line in caption_data:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            # 画像名とキャプションはタブで区切られる\n",
    "            img_name, caption = line.split(\"\\t\")\n",
    "\n",
    "            # 各画像は、5つの異なるキャプションのために5回繰り返される。\n",
    "            # 各画像には接頭辞`#(caption_number)`が付く。\n",
    "            img_name = img_name.split(\"#\")[0]\n",
    "            img_name = os.path.join(IMAGES_PATH, img_name.strip())\n",
    "\n",
    "            # 短すぎるキャプションや長すぎるキャプションは削除する\n",
    "            tokens = caption.strip().split()\n",
    "\n",
    "            if len(tokens) < 5 or len(tokens) > SEQ_LENGTH:\n",
    "                images_to_skip.add(img_name)\n",
    "                continue\n",
    "\n",
    "            if img_name.endswith(\"jpg\") and img_name not in images_to_skip:\n",
    "                # それぞれのキャプチョンに開始トークンと終了トークンを追加する\n",
    "                caption = \"<start> \" + caption.strip() + \" <end>\"\n",
    "                text_data.append(caption)\n",
    "\n",
    "                if img_name in caption_mapping:\n",
    "                    caption_mapping[img_name].append(caption)\n",
    "                else:\n",
    "                    caption_mapping[img_name] = [caption]\n",
    "        \n",
    "        for img_name in images_to_skip:\n",
    "            if img_name in caption_mapping:\n",
    "                del caption_mapping[img_name]\n",
    "\n",
    "        return caption_mapping, text_data\n",
    "    \n",
    "\n",
    "def train_val_split(caption_data, train_size = 0.8, shuffle=True):\n",
    "    \"\"\"キャプションデータセットを訓練と検証データセットに分ける\n",
    "    \n",
    "    Args:\n",
    "        caption_data (dict): マッピングされたキャプションデータを含むディクショナリ\n",
    "        train_size (float): 全データセットのうち、トレーニングデータとして使用するデータセットの割合\n",
    "        shufflw (bool): 分割前にデータセットをシャッフルするかどうか\n",
    "        \n",
    "    Returns:\n",
    "        訓練データセットと検証データセットを、2つの分離されたディクショナリとして扱う\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_ml_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
